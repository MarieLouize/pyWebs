{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as playwrightTimeout\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of years\n",
    "SEASONS= list(range(2018, 2026))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switching playwright with beautiful soup and requests\n",
    "def get_html(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = Path().resolve()\n",
    "standings_dir = base_dir / \"standings_dir\"\n",
    "\n",
    "#function that scrapes the standings table and saves the links of monthly box scores\n",
    "def get_month_links(season):\n",
    "    base_url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    filter_div = soup.find('div', class_='filter')\n",
    "    links = filter_div.find_all('a')\n",
    "    month_urls = ['https://www.basketball-reference.com' + a['href'] for a in links]\n",
    "\n",
    "    for link in month_urls:\n",
    "        month = link.split('_')[-1].split('.')[0]  # e.g. \"october\"\n",
    "        month_response = requests.get(link)\n",
    "        month_soup = BeautifulSoup(month_response.text, 'html.parser')\n",
    "\n",
    "        table = month_soup.select_one('#all_schedule')\n",
    "        if table:\n",
    "            file_path = standings_dir / f\"{season}_{month}.html\"\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(str(table))\n",
    "            print(f\"Saved {file_path}\")\n",
    "        else:\n",
    "            print(f\"No table found on {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-october.html\n",
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-november.html\n",
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-december.html\n",
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-january.html\n",
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-february.html\n",
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-march.html\n",
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-april.html\n",
      "Saved /Users/user/Desktop/Code/pyWebs/notebooks/standings_dir/2025_games-may.html\n"
     ]
    }
   ],
   "source": [
    "get_month_links(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to save yearly advanced stats \n",
    "def advanced_stats(year):\n",
    "    base_url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
    "    # Send HTTP request to the URL to avoid being blocked again\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(base_url, headers=headers)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', id='advanced')\n",
    "    \n",
    "    if not table:\n",
    "        raise Exception(\"Advanced stats table not found on the page\")\n",
    "    \n",
    "    # Convert table to DataFrame\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "    \n",
    "    # Clean the DataFrame\n",
    "    # Remove rows that are used as header separators in the table\n",
    "    df = df[~df['Player'].str.contains('Player', na=False)]\n",
    "    \n",
    "    # Remove duplicate column headers that appear in the middle of the table\n",
    "    df = df[df['Rk'] != 'Rk']\n",
    "    \n",
    "    # Reset the index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Create 'advance' directory if it doesn't exist\n",
    "    os.makedirs('advance', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = f\"advance/nba_advanced_stats_{year}.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Advanced stats for {year} NBA season saved to {output_path}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced stats for 2025 NBA season saved to advance/nba_advanced_stats_2025.csv\n",
      "Data saved to: advance/nba_advanced_stats_2025.csv\n"
     ]
    }
   ],
   "source": [
    "#scraped all the years one by one, gave like a minute interval \n",
    "year = 2025\n",
    "file_path = advanced_stats(year)\n",
    "print(f\"Data saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save yearly per_game stats\n",
    "def per_game_stats(year):\n",
    "    base_url = f\"https://basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', id='per_game_stats')\n",
    "    \n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "    df = df[~df['Player'].str.contains('Player', na=False)]\n",
    "    \n",
    "    df = df[df['Rk'] != 'Rk']\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    os.makedirs('per_game_stats', exist_ok=True)\n",
    "\n",
    "    output_path = f\"per_game_stats/nba_per_game_stats_{year}.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Per_game stats for {year} NBA season saved to {output_path}\")\n",
    "    return output_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per_game stats for 2025 NBA season saved to per_game_stats/nba_per_game_stats_2025.csv\n",
      "Data saved to: per_game_stats/nba_per_game_stats_2025.csv\n"
     ]
    }
   ],
   "source": [
    "year = 2025\n",
    "file_path = per_game_stats(year)\n",
    "print(f\"Data saved to: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
